# üöÄ Performance Optimization for 300+ Stores

## üìä Performance Comparison

### Before Optimization (Sequential Processing)

```
‚ùå OLD METHOD - SEQUENTIAL SYNC

User Sync:
‚îú‚îÄ Store 1: 3 seconds + 1 sec delay = 4 sec
‚îú‚îÄ Store 2: 3 seconds + 1 sec delay = 4 sec
‚îú‚îÄ ... (sequentially)
‚îî‚îÄ Store 300: 3 seconds + 1 sec delay = 4 sec
TOTAL: 300 √ó 4 = 1,200 seconds = 20 minutes

Video Sync:
‚îú‚îÄ Store 1: 7 seconds + 2 sec delay = 9 sec
‚îú‚îÄ Store 2: 7 seconds + 2 sec delay = 9 sec
‚îú‚îÄ ... (sequentially)
‚îî‚îÄ Store 300: 7 seconds + 2 sec delay = 9 sec
TOTAL: 300 √ó 9 = 2,700 seconds = 45 minutes

TOTAL SYNC TIME: 20 + 45 = 65 MINUTES ‚ùå
```

### After Optimization (Parallel Processing)

```
‚úÖ NEW METHOD - PARALLEL SYNC WITH BATCHING

User Sync (30 concurrent):
‚îú‚îÄ Batch 1: 30 stores √ó 3 sec = 3 sec (parallel)
‚îú‚îÄ Batch 2: 30 stores √ó 3 sec = 3 sec (parallel)
‚îú‚îÄ ... (10 batches)
‚îî‚îÄ Batch 10: 30 stores √ó 3 sec = 3 sec (parallel)
TOTAL: 10 batches √ó 3 sec = 30 seconds + overhead = ~2-3 minutes

Video Sync (20 concurrent):
‚îú‚îÄ Batch 1: 20 stores √ó 7 sec = 7 sec (parallel)
‚îú‚îÄ Batch 2: 20 stores √ó 7 sec = 7 sec (parallel)
‚îú‚îÄ ... (15 batches)
‚îî‚îÄ Batch 15: 20 stores √ó 7 sec = 7 sec (parallel)
TOTAL: 15 batches √ó 7 sec = 105 seconds + overhead = ~5-8 minutes

TOTAL SYNC TIME: 3 + 8 = 11 MINUTES ‚úÖ
```

### Performance Gain

| Metric | Before | After | Improvement |
|--------|--------|-------|-------------|
| User Sync | 20 min | 2-3 min | **83% faster** |
| Video Sync | 45 min | 5-8 min | **82% faster** |
| **Total** | **65 min** | **11 min** | **‚ö° 6x FASTER** |

---

## üîß Optimizations Implemented

### 1. Batch Processing Utility (`src/utils/batch.ts`)

```typescript
// Process 300 stores in parallel batches of 30
await batchProcess(
  stores,
  async (store) => syncStore(store),
  {
    concurrency: 30,           // 30 parallel operations
    onProgress: (done, total) => {
      console.log(`Progress: ${done}/${total}`);
    }
  }
);
```

**Benefits**:
- ‚úÖ Controlled concurrency (prevent system overload)
- ‚úÖ Progress tracking
- ‚úÖ Error handling per item
- ‚úÖ Automatic retry support

### 2. Database Pool Optimization

**Before**: 20 connections ‚Üí **After**: 100 connections

```typescript
// src/db/client.ts
const pool = new Pool({
  max: 100,              // Handle 100 concurrent operations
  min: 20,               // Keep 20 idle connections warm
  connectionTimeoutMillis: 10000,
});
```

**Benefits**:
- ‚úÖ Support 30+ concurrent syncs without connection exhaustion
- ‚úÖ Faster connection acquisition
- ‚úÖ Reduced contention

### 3. Parallel Sync Jobs

**User Sync** (`src/jobs/syncUserDaily.job.ts`):
- Concurrency: 30 stores (configurable via `SYNC_CONCURRENCY`)
- Real-time progress logging
- Graceful error handling

**Video Sync** (`src/jobs/syncVideoDaily.job.ts`):
- Concurrency: 20 stores (configurable via `VIDEO_SYNC_CONCURRENCY`)
- Lower concurrency due to more API calls per store
- Video count tracking

---

## ‚öôÔ∏è Configuration Guide

### Environment Variables

```bash
# Database Pool (adjust based on your PostgreSQL max_connections)
DB_POOL_SIZE=100              # Recommended: 100 for 300+ stores
DB_POOL_MIN=20                # Keep 20 connections idle

# Sync Concurrency
SYNC_CONCURRENCY=30           # User sync: 30 concurrent stores
VIDEO_SYNC_CONCURRENCY=20     # Video sync: 20 concurrent stores
```

### Tuning Guide

#### For 300 Stores

| Your Setup | DB_POOL_SIZE | SYNC_CONCURRENCY | VIDEO_SYNC_CONCURRENCY |
|------------|--------------|------------------|------------------------|
| Basic (2 CPU, 4GB RAM) | 50 | 15 | 10 |
| Standard (4 CPU, 8GB RAM) | 100 | 30 | 20 |
| High-End (8+ CPU, 16GB RAM) | 150 | 50 | 30 |

#### For 500+ Stores

| Your Setup | DB_POOL_SIZE | SYNC_CONCURRENCY | VIDEO_SYNC_CONCURRENCY |
|------------|--------------|------------------|------------------------|
| Standard (4 CPU, 8GB RAM) | 100 | 40 | 25 |
| High-End (8+ CPU, 16GB RAM) | 200 | 60 | 40 |

#### For 1000+ Stores

Consider:
- Multiple backend instances (horizontal scaling)
- Redis for distributed locking
- Dedicated sync worker instances

---

## üìà Monitoring

### Check Sync Progress

```bash
# Watch logs in real-time
docker-compose logs -f backend | grep "Sync progress"

# Output example:
# {"processed":30,"total":300,"percent":10,"msg":"Sync progress"}
# {"processed":60,"total":300,"percent":20,"msg":"Sync progress"}
```

### Monitor Database Pool

```bash
# Logs every minute in production
docker-compose logs backend | grep "Database pool statistics"

# Output example:
# {"totalCount":45,"idleCount":20,"waitingCount":0,"msg":"Database pool statistics"}
```

### Check Sync Performance

```sql
-- Last 10 sync jobs with duration
SELECT 
  job_name,
  status,
  message,
  duration_ms / 1000 as duration_sec,
  run_time
FROM sync_logs
WHERE store_code IS NULL
ORDER BY run_time DESC
LIMIT 10;
```

---

## üéØ Performance Tips

### 1. TikTok API Rate Limits

TikTok has rate limits per app:
- Monitor for `429 Too Many Requests` errors
- If you hit rate limits, reduce concurrency:

```bash
SYNC_CONCURRENCY=20           # Reduce from 30
VIDEO_SYNC_CONCURRENCY=15     # Reduce from 20
```

### 2. Database Optimization

```sql
-- Check PostgreSQL max_connections
SHOW max_connections;

-- Recommended: Set to DB_POOL_SIZE + 50
-- Example: If DB_POOL_SIZE=100, set max_connections=150

-- In postgresql.conf:
max_connections = 150
```

### 3. Server Resources

Monitor during sync:
```bash
# CPU usage
docker stats backend

# Memory usage
docker stats backend --format "{{.MemUsage}}"

# If high CPU (>80%), reduce concurrency
# If high memory (>80%), reduce concurrency or increase server RAM
```

### 4. Network Bandwidth

300 stores √ó 2MB avg = ~600MB data transfer
- Ensure good network connection to TikTok API
- Monitor network latency

---

## üö® Troubleshooting

### Issue: Slow Sync (>15 minutes for 300 stores)

**Possible causes**:
1. **Low concurrency** ‚Üí Increase `SYNC_CONCURRENCY`
2. **Database pool exhaustion** ‚Üí Increase `DB_POOL_SIZE`
3. **TikTok API slow response** ‚Üí Check network latency
4. **Server overload** ‚Üí Check CPU/RAM usage

### Issue: Database connection errors

**Error**: `connect ECONNREFUSED` or `connection timeout`

**Solutions**:
1. Reduce `DB_POOL_SIZE`
2. Increase PostgreSQL `max_connections`
3. Check database server resources

### Issue: TikTok API errors (429)

**Error**: `Too Many Requests`

**Solutions**:
1. Reduce concurrency settings
2. Add delays between batches:
   ```typescript
   // In src/jobs/syncUserDaily.job.ts
   delayBetweenBatches: 1000  // 1 second delay
   ```

### Issue: Memory leaks

**Symptoms**: Memory usage keeps growing

**Solutions**:
1. Restart backend periodically (e.g., weekly)
2. Check for unclosed database connections
3. Monitor with:
   ```bash
   docker stats backend --no-stream
   ```

---

## üìä Expected Results

For **300 stores**:

| Metric | Target | Acceptable | Poor |
|--------|--------|------------|------|
| User Sync | < 3 min | 3-5 min | > 5 min |
| Video Sync | < 8 min | 8-12 min | > 12 min |
| Total | < 11 min | 11-17 min | > 17 min |
| Success Rate | > 95% | 90-95% | < 90% |
| DB Pool Usage | < 70% | 70-85% | > 85% |

---

## üéñÔ∏è Best Practices

1. **Schedule syncs during low-traffic hours** (e.g., 2-4 AM)
2. **Monitor sync logs daily** for failures
3. **Set up alerts** for sync duration > 15 minutes
4. **Keep PostgreSQL updated** (use v14+)
5. **Use SSD for database** (10x faster than HDD)
6. **Enable connection pooling** in your database
7. **Use CDN/caching** for API responses if possible

---

## üöÄ Next Steps (Optional Enhancements)

### For 500+ stores or multiple backend instances:

1. **Redis Integration**
   - Distributed rate limiting
   - Token caching (reduce decryption overhead)
   - Distributed locking

2. **Queue System (Bull/BullMQ)**
   - Better job management
   - Retry logic
   - Job prioritization

3. **Horizontal Scaling**
   - Multiple backend instances
   - Load balancer
   - Shared Redis for coordination

4. **Monitoring Dashboard**
   - Grafana + Prometheus
   - Real-time sync progress
   - Alert on failures

---

## üìù Summary

‚úÖ **Optimization implemented**:
- Parallel batch processing (30 concurrent user syncs, 20 concurrent video syncs)
- Database pool increased (20 ‚Üí 100 connections)
- Progress tracking and monitoring
- Configurable concurrency via environment variables

‚ö° **Performance improvement**:
- **Before**: 65 minutes for 300 stores
- **After**: 11 minutes for 300 stores
- **Speedup**: **6x faster** (83% reduction in sync time)

üéØ **Production ready** for 300+ stores with current implementation.
